{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QACY3c_lr4uz"
      },
      "source": [
        "# Lab04: Wiki Indexer.\n",
        "\n",
        "- MSSV: 19120689\n",
        "- Họ và tên: Lại Khánh Toàn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD8WblEMr4u1"
      },
      "source": [
        "## Yêu cầu bài tập\n",
        "\n",
        "**Cách làm bài**\n",
        "\n",
        "\n",
        "Bạn sẽ làm trực tiếp trên file notebook này; từ `TODO` cho biết những phần mà bạn cần phải làm.\n",
        "\n",
        "Bạn có thể thảo luận ý tưởng cũng như tham khảo các tài liệu, nhưng *code và bài làm phải là của bạn*. \n",
        "\n",
        "Nếu vi phạm thì sẽ bị 0 điểm cho bài tập này.\n",
        "\n",
        "**Cách nộp bài**\n",
        "\n",
        "Trước khi nộp bài, rerun lại notebook (`Kernel` -> `Restart & Run All`).\n",
        "\n",
        "Sau đó, tạo thư mục có tên `MSSV` của bạn (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`) Chép file notebook, file `data.json` và file `inverted_index.json` vào thư mục của các bạn (nếu file này kích thước lớn các bạn có thể chép link vào `link_data.txt`), nén thư mục `MSSV` này lại và nộp trên moodle.\n",
        "\n",
        "**Nội dung bài tập**\n",
        "Dựa trên dữ liệu từ wiki, xây dựng inverted_index và tiến hành tìm kiếm dữ liệu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txFiZE0Zr4u2"
      },
      "source": [
        "## Nội dung bài tập"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDREKsiC5K6Q"
      },
      "source": [
        "### Thư viện mediawiki\n",
        "\n",
        "- mediawiki is a python wrapper and parser for the MediaWiki API. The goal is to allow users to quickly and efficiently pull data from the MediaWiki site of their choice instead of worrying about dealing directly with the API\n",
        "- For more information: https://pymediawiki.readthedocs.io/en/latest/quickstart.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su_weRPD5S85",
        "outputId": "a0c87afc-97b0-4a60-b0b1-3b967fcd8eb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymediawiki\n",
            "  Downloading pymediawiki-0.7.2-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from pymediawiki) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from pymediawiki) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.0.0->pymediawiki) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->pymediawiki) (2.4.1)\n",
            "Installing collected packages: pymediawiki\n",
            "Successfully installed pymediawiki-0.7.2\n"
          ]
        }
      ],
      "source": [
        "pip install pymediawiki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7Ivi0x_5K6R",
        "outputId": "141f3806-e578-434a-c863-6a4f410e937c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mediawiki'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-2d32106affcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmediawiki\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMediaWiki\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwikipedia\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMediaWiki\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediawiki'"
          ]
        }
      ],
      "source": [
        "from mediawiki import MediaWiki\n",
        "import json\n",
        "\n",
        "wikipedia = MediaWiki(lang='en')\n",
        "\n",
        "rp = wikipedia.random(pages=2)\n",
        "p = wikipedia.page(rp[0])\n",
        "print(p.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feKRlSvi5K6S"
      },
      "source": [
        "# Lấy dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLmpse6T5K6S"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "#Lấy dữ liệu từ wiki\n",
        "def getWikiContent(num_page):\n",
        "    # Dữ liệu sẽ được lưu theo dạng\n",
        "    # [\n",
        "    #     {\n",
        "    #         \"id\": ....,\n",
        "    #         \"url\": ....,\n",
        "    #         \"title\": ...,\n",
        "    #         \"content\": ...,\n",
        "    #     },\n",
        "    #     {\n",
        "    #         \"id\": ....,\n",
        "    #         \"url\": ....,\n",
        "    #         \"title\": ...,\n",
        "    #         \"content\": ...,\n",
        "    #     }\n",
        "    #     ...\n",
        "    # ]\n",
        "    # id: được đánh số từ 1->5000 \n",
        "    data = []\n",
        "\n",
        "    for i in range(num_page):\n",
        "        page = wikipedia.random(pages=1)\n",
        "        p = wikipedia.page(page[0])\n",
        "        data.append({\n",
        "            \"id\": i+1,\n",
        "            \"url\": p.url,\n",
        "            \"title\": p.title,\n",
        "            \"content\": p.content\n",
        "        })\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzMvdynd5K6S"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "# Lưu dữ liệu vào file 'data.json'\n",
        "def saveWikiContent(data):\n",
        "    with open('data.json', 'w') as f:\n",
        "        json.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdnUVCZ35K6S"
      },
      "outputs": [],
      "source": [
        "#Sử dụng dữ liệu được lấy từ 5000 trang wikipedia ngẫu nhiên\n",
        "num_page = 5000\n",
        "wiki_content = getWikiContent(num_page)\n",
        "saveWikiContent(wiki_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XRwqWv05K6T"
      },
      "source": [
        "# Load dữ liệu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8MGqyRJ5K6T"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "#Load dữ liệu từ file dữ liệu đã lưu\n",
        "def loadData(file_name):\n",
        "    with open(file_name, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZj4GvOz5K6T"
      },
      "outputs": [],
      "source": [
        "file_name = \"data.json\"\n",
        "wiki_content = loadData(file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chkEuAan5K6T"
      },
      "source": [
        "# Inverted-Index\n",
        "Inverted index is a data structure used in information retrieval systems to efficiently retrieve documents or web pages containing a specific term or set of terms. In an inverted index, the index is organized by terms (words), and each term points to a list of documents or web pages that contain that term.\n",
        "\n",
        "For example, consider the following documents:\n",
        "\n",
        "    Document 1: The quick brown fox jumped over the lazy dog.\n",
        "    Document 2: The lazy dog slept in the sun.\n",
        "\n",
        "To create an inverted index for these documents, we first tokenize the documents into terms, as follows:\n",
        "\n",
        "    Document 1: The, quick, brown, fox, jumped, over, the, lazy, dog.\n",
        "    Document 2: The, lazy, dog, slept, in, the, sun.\n",
        "\n",
        "Next, we create an index of the terms, where each term points to a list of documents that contain that term, as follows:\n",
        "\n",
        "    The -> Document 1, Document 2\n",
        "    quick -> Document 1\n",
        "    brown -> Document 1\n",
        "    fox -> Document 1\n",
        "    jumped -> Document 1\n",
        "    over -> Document 1\n",
        "    lazy -> Document 1, Document 2\n",
        "    dog -> Document 1, Document 2\n",
        "    slept -> Document 2\n",
        "    in -> Document 2\n",
        "    sun -> Document 2\n",
        "\n",
        "To search for documents containing a particular term or set of terms, the search engine queries the inverted index for those terms and retrieves the list of documents associated with each term. The search engine can then use this information to rank the documents based on relevance to the query and present them to the user in order of importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suZmNgpQ5K6T"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "#Xử lý dữ liệu\n",
        "\n",
        "def processData(data):\n",
        "    #trong mỗi trường dữ liệu title, content thực hiện việc xử lý dữ liệu\n",
        "\n",
        "    # loại bỏ kí tự đặc biệt\n",
        "    # tách từ\n",
        "\n",
        "    # chuyển đổi dữ liệu về chữ thường\n",
        "\n",
        "    # Loại bỏ các từ mà nằm trong danh sách english_stopwords\n",
        "\n",
        "    # Loại bỏ các từ không phải tiếng anh\n",
        "\n",
        "    # chuyển từ về dạng nguyên gốc (stemming)\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        data[i]['title'] = data[i]['title'].lower()\n",
        "        data[i]['content'] = data[i]['content'].lower()\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TkVEbeM5K6T"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "#Tính toán inverted index\n",
        "def invertedIndex(data):\n",
        "    # thực hiện việc tính inverted index cho riêng title, content\n",
        "    # lưu inverted_index dưới dạng\n",
        "    # {\n",
        "    #     \"word1\": {\n",
        "    #         \"t\": [id1, id2,...], (inverted index cho title)\n",
        "    #         \"c\" : [id2, id4,...], (inverted index cho content)\n",
        "    #     },\n",
        "    #     \"word2\": {\n",
        "    #         \"t\": [id1, id2,...], (inverted index cho title)\n",
        "    #         \"c\" : [id2, id4,...], (inverted index cho content)\n",
        "    #     },\n",
        "    # }\n",
        "\n",
        "    inverted_index = {}\n",
        "    for i in range(len(data)):\n",
        "        for word in data[i]['title'].split():\n",
        "            if word not in inverted_index:\n",
        "                inverted_index[word] = {\n",
        "                    \"t\": [data[i]['id']],\n",
        "                    \"c\": []\n",
        "                }\n",
        "            else:\n",
        "                if data[i]['id'] not in inverted_index[word]['t']:\n",
        "                    inverted_index[word]['t'].append(data[i]['id'])\n",
        "        for word in data[i]['content'].split():\n",
        "            if word not in inverted_index:\n",
        "                inverted_index[word] = {\n",
        "                    \"t\": [],\n",
        "                    \"c\": [data[i]['id']]\n",
        "                }\n",
        "            else:\n",
        "                if data[i]['id'] not in inverted_index[word]['c']:\n",
        "                    inverted_index[word]['c'].append(data[i]['id'])\n",
        "\n",
        "    return inverted_index\n",
        "\n",
        "#TODO\n",
        "#Lưu dữ liệu inverted index\n",
        "def saveFileIndex(data):\n",
        "    #Lưu inverted_index vào file \"inverted_index.json\"\n",
        "    with open('inverted_index.json', 'w') as f:\n",
        "        json.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyW5Zqe_5K6U"
      },
      "outputs": [],
      "source": [
        "data = processData(wiki_content)\n",
        "\n",
        "inverted_index = invertedIndex(data)\n",
        "\n",
        "saveFileIndex(inverted_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6yB6rD25K6U"
      },
      "source": [
        "# Tìm kiếm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IG8Eorl5K6U"
      },
      "outputs": [],
      "source": [
        "inverted_index = loadData(\"inverted_index.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNVoPd2v5K6U"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "# Tìm kiếm dữ liệu có chứa query\n",
        "# Trả về id của các bộ document phù hợp \n",
        "def search(query):\n",
        "    \n",
        "    # xử lý câu query (tương tự xử lý dữ liệu wiki)\n",
        "\n",
        "    # Tìm kiếm dữ liệu có chứa từ trong query\n",
        "\n",
        "    # Thứ tự tìm kiếm ưu tiên:  ưu tiên tìm xem có document nào chứa tất cả từ trong query không, \n",
        "    # nếu không có thì bắt đầu tìm document chứa một vài từ có trong query\n",
        "    \n",
        "    # Độ ưu tiên khi thực hiện tìm kiếm dữ liệu: ưu tiên tìm kiếm query nằm trong title trước, sau đó tìm kiếm query nằm trong content. \n",
        "    # Nếu document đó đã xuất hiện query trong title rồi thì không tìm kiếm trong content nữa\n",
        "    \n",
        "    # Danh sách kết quả các id của document tìm được được sắp xếp theo: \n",
        "    # Các document có query xuất hiện trong title(từ có các document chứa nhiều từ query nhất đến ít từ query xuất hiện nhất)\n",
        "    # Các document có query xuất hiện trong content(từ có các document chứa nhiều từ query nhất đến ít từ query xuất hiện nhất)\n",
        "    id_list = []\n",
        "    query = query.lower()\n",
        "    query = query.split()\n",
        "    for word in query:\n",
        "        if word in inverted_index:\n",
        "            for id in inverted_index[word]['t']:\n",
        "                if id not in id_list:\n",
        "                    id_list.append(id)\n",
        "            for id in inverted_index[word]['c']:\n",
        "                if id not in id_list:\n",
        "                    id_list.append(id)\n",
        "                    \n",
        "    \n",
        "\n",
        "    return id_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGaXA1pS5K6U"
      },
      "outputs": [],
      "source": [
        "search('web mining')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WUJrUDF5K6U"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "#Đánh giá thời gian thực hiện với các câu query từ 1 đến 5 từ => Đưa ra nhận xét"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
